# configs/gaussian.yaml
output_dir: "experiments/gaussian"

model:
  n_positions: 60          # Total positions in sequence
  d_model: 256             # Embedding dimension
  n_layer: 12              # Number of transformer layers  
  n_head: 8                # Number of attention heads
  kernel_type: "softmax"   # Type of kernel (transformer or softmax)

task:
  name: "gaussian"         # Distribution name

training:
  batch_size: 64
  n_batches: 1000
  n_epochs: 20
  learning_rate: 0.003
  save_every: 500
  eval_every: 100
  patience: 30
  train_steps: 20000
  warmup_steps: 500
  steps_per_epoch: 100
  n_val_tasks: 5
  n_test_tasks: 2
  grad_clip: 1.0
  weight_decay: 0.01
  keep_every_steps: 5000   # Save model snapshot every this many steps

  # Curriculum learning parameters
  min_points: 60           # Use full sequence length (no curriculum on points)
  min_dims: 2              # Start with this many dimensions
  point_schedule: 0        # Disable point curriculum
  dim_schedule: 0.8        # Reach max dimensions after 80% of training
  
  # Control the number of unique random distributions seen during training
  # If set, model will only train on this many different distributions
  # Useful for testing memorization vs. generalization
  num_unique_distributions: null  # null means no limit (infinite distributions)

logging:
  use_wandb: false
  project_name: "prob-icl"
  log_every: 100 