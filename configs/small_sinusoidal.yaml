# configs/small_sinusoidal.yaml
output_dir: "experiments/small_sinusoidal"

# Smaller model for faster training and testing

model:
  model_type: "gpt2"        # Use GPT2-style model to match original repo
  n_layer: 4                # Reduced from 12 to 4 layers
  n_positions: 41           # Total positions in sequence
  n_dims: 1                 # Input dimensionality (1D is sufficient for sinusoidal)
  d_model: 128              # Reduced from 256 to 128 embedding dimension
  n_heads: 4                # Reduced from 8 to 4 attention heads
  kernel_type: "softmax"    # Type of kernel

task:
  name: "sinusoidal"        # Task name (must match the key in task_map)
  task_scale: 1.0           # Scale of the task (affects amplitude)
  x_range: 5.0              # Input range for uniform sampling (-x_range, x_range)
  freq_min: 0.5             # Minimum frequency for the sine wave
  freq_max: 2.0             # Maximum frequency for the sine wave

training:
  batch_size: 64
  train_steps: 5000         # Reduced training steps since we expect faster convergence
  learning_rate: 1e-4
  grad_clip: 1.0
  save_every: 500
  eval_every: 100
  n_val_tasks: 5
  
  # Curriculum learning parameters (only for dimensions)
  min_dims: 1              # Start with full dimensions as in original
  dim_schedule: 0          # No dimension curriculum
  
  # Point settings
  min_points: 41           # Same as n_positions
  point_schedule: 0        # Disable point curriculum
  
  # Optional settings for task pools/seeds
  num_unique_distributions: null  # null means no limit (infinite distributions)
  pool_size: null          # Optional: create a fixed pool of tasks

logging:
  use_wandb: false
  project_name: "prob-icl"
  log_every: 100 