# configs/gamma.yaml
model:
  n_dims: 10
  n_positions: 100
  n_embd: 384
  n_layer: 8
  n_head: 12

training:
  batch_size: 32
  learning_rate: 0.0003
  train_steps: 30000
  eval_every: 500
  save_every: 1000
  patience: 15
  seed: 42

task:
  task_name: gamma
  task_scale: 1.0

logging:
  use_wandb: false
  project_name: prob-icl
  log_every: 100

output_dir: outputs 